{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDgYAuF+GB49da3hbNGQt0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36a7064380f644f7a700e985bca772f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_251cade274e2440fbcffec13b6acfb15",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d42372a0fbcf4924a17da5eec6060f2c",
              "IPY_MODEL_66f2063fa86c44afa12ad570c8c499e0"
            ]
          }
        },
        "251cade274e2440fbcffec13b6acfb15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d42372a0fbcf4924a17da5eec6060f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_600c67f93a934d88ad554f9b44010631",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4300cb0334f7403795ec490f3704b581"
          }
        },
        "66f2063fa86c44afa12ad570c8c499e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_baf762f037e840cfba67a873e14ce46d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:19&lt;00:00, 78979492.57it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_edb84c089f6a4dfa89c774ec0a668bdd"
          }
        },
        "600c67f93a934d88ad554f9b44010631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4300cb0334f7403795ec490f3704b581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "baf762f037e840cfba67a873e14ce46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "edb84c089f6a4dfa89c774ec0a668bdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvdheram/DeepLearning-Notebooks/blob/main/Introduction_to_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5NdjwOQX0qj"
      },
      "source": [
        "# Introduction "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzPQCYsCQO3A"
      },
      "source": [
        "Deep learning vs Machine learning\n",
        "\n",
        "Machine Learning: \n",
        "\n",
        "* Feature Engineering (selection of \n",
        " **appropriate** features) is to be done before training. \n",
        "* Fits a straight line (Linearly seperable).\n",
        "\n",
        "Deep Learning: \n",
        "\n",
        "* Feature Engineering (Extraction and selection of **appropriate** features) happens during training.\n",
        "  * Eg.Image Classification, speech recognition, text etc.\n",
        "* Fits a squiggly line (Non-linear seperable).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjKmCJY5igVL"
      },
      "source": [
        "Why PyTorch ?\n",
        "\n",
        "* Pythonic.\n",
        "* GPU support.\n",
        "* Similar to NumPy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9Z1SVtRlGrS"
      },
      "source": [
        "## Defining tensor "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLZHYnF7ODcC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "367b9f74-8820-4c6d-c139-8927b9fbd3d3"
      },
      "source": [
        "# Tensor using torch ( Tensor: Array with arbitrary number of dimensions )\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 2x3 Tensor\n",
        "torch.tensor([[2,3,4],[1,2,9]])\n",
        "\n",
        "# Random 2x2 matrix\n",
        "torch.rand(2,2)\n",
        "\n",
        "# variable to matrix\n",
        "a = torch.rand((3,5))\n",
        "a.shape\n",
        "\n",
        "# 2x2 of 0's\n",
        "a = torch.zeros(2,2)\n",
        "\n",
        "# 2x2 of 1's\n",
        "b = torch.ones(2,2)\n",
        "\n",
        "# Identity Matrix\n",
        "c = torch.eye(2)\n",
        "\n",
        "# Convert from numpy\n",
        "c_numpy = np.identity(2)\n",
        "d_torch = torch.from_numpy(c_numpy)\n",
        "\n",
        "print(a , \"\\n\\n\", b,\"\\n \\n\",c,\"\\n\\n\",d_torch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]]) \n",
            "\n",
            " tensor([[1., 1.],\n",
            "        [1., 1.]]) \n",
            " \n",
            " tensor([[1., 0.],\n",
            "        [0., 1.]]) \n",
            "\n",
            " tensor([[1., 0.],\n",
            "        [0., 1.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IToAo8qLlqvB"
      },
      "source": [
        "## Matrix Operations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLG88ukljdYI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "b3260f8c-3225-46ed-a0a1-c912f9c92774"
      },
      "source": [
        "a = torch.tensor([[1,2],[3,4]])\n",
        "b = torch.tensor([[5,6],[7,8]])\n",
        "\n",
        "print(a , \"\\n\\n\", b,\"\\n \\n\")\n",
        "torch.matmul(a,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            "\n",
            " tensor([[5, 6],\n",
            "        [7, 8]]) \n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19, 22],\n",
              "        [43, 50]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmstf2yPyL4R"
      },
      "source": [
        "# Forward Passing in NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C81yb1fP80ee"
      },
      "source": [
        "*Neural networks can be understood as **computational graphs**.* \n",
        "\n",
        "**Computational Graphs** is a network of nodes which represents scalars, vectors or tensors connected via edges which represents functions of operation.\n",
        "\n",
        "* Under the hood code gets converted into computational graphs which makes automatic computation of gradients/ derivatives easier.\n",
        "\n",
        "NeuralNetworks\n",
        "                  \n",
        "    Input Layer -> Weighted sum of inputs -> Activation function on the weighted sum.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPZV9xRMyO5F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "759f2591-df22-447f-fead-efdc4251bc61"
      },
      "source": [
        "# Simple computational graph with functions(addition and multiplication) performed on scalars.\n",
        "\n",
        "import torch\n",
        "\n",
        "a = torch.Tensor([2])\n",
        "b = torch.Tensor([-4])\n",
        "c = torch.Tensor([-2])\n",
        "d = torch.Tensor([2])\n",
        "\n",
        "e = a+b\n",
        "f = c*d\n",
        "\n",
        "g = e*f\n",
        "print(e,f,g)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-2.]) tensor([-4.]) tensor([8.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epdHBs0gAC4q"
      },
      "source": [
        "# Backpropagation \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U-mugw2B4Ns"
      },
      "source": [
        "## Derivatives \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mpAarT6B8Le"
      },
      "source": [
        "* Rate of change of function.\n",
        "* Can be interpreted as indicating the Steepness of function.\n",
        "\n",
        "Derivative Rules :\n",
        "\n",
        "    d - Derivative w.r.t x\n",
        "\n",
        "    Addition : (f+g)' = f'+g'\n",
        "    Multiplication : (f.g)' = f.dg + g.df\n",
        "    d[3x] = 3\n",
        "    d[constant] = 0\n",
        "    d[x] = 1\n",
        "\n",
        "* Chain Rule:\n",
        "  * Deals with composition of fuctions (function g inside f).\n",
        "         d[f(g(x))] = f'(g(x))* g'(x)\n",
        "         d[(f(x))^n] = n(f(x))^n-1 * f'(x)\n",
        "  * Eg. \n",
        "        1. d[(sin x)^2)] \n",
        "        \n",
        "         = d/d(sinx) [(sinx)^2] * d/dx [sinx]\n",
        "         = 2 sinx + cos x\n",
        "\n",
        "        2. d[(x+2)^2]\n",
        "\n",
        "        = d/d(x+2) [(x+2)^2] * d/dx [x+2]\n",
        "        = 2x+4\n",
        "\n",
        "**Chain rule used in backprop to readjust the weights** . \n",
        "\n",
        "\n",
        " Note :\n",
        "\n",
        "* Gradient is multi-variable generalization of derivative.\n",
        "\n",
        "* Considering many variable in NN. **\"Gradient\" is used instead of \"derivative\"**. \n",
        "\n",
        "\n",
        "\n",
        "  \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7Ha0vaRB3rR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "88728348-93e3-417d-92f3-8831363f60b2"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Required grad set to true for derivatives\n",
        "x = torch.tensor(-3., requires_grad= True)\n",
        "y = torch.tensor(5., requires_grad= True)\n",
        "z = torch.tensor(-2.,requires_grad= True)\n",
        "\n",
        "q = x+y\n",
        "f = q*z\n",
        "\n",
        "# Compute derivative of the computational graph\n",
        "f.backward()\n",
        "\n",
        "print(\"Gradient of z is \", str(z.grad))\n",
        "print(\"Gradient of y is \", str(y.grad))\n",
        "print(\"Gradient of x is \", str(x.grad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient of z is  tensor(2.)\n",
            "Gradient of y is  tensor(-2.)\n",
            "Gradient of x is  tensor(-2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpydSFVc94oD"
      },
      "source": [
        "# Neural network\n",
        "\n",
        "ANN vs other classifiers\n",
        "\n",
        "* Features are extracted as a part of the network (Input layers).\n",
        "  Eg. Speech recognition, image classification etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66H1nmOD7zwt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0267584f-9af4-483a-a39d-5da30c3a8f0d"
      },
      "source": [
        "import torch\n",
        "\n",
        "# 10 nodes of input layer\n",
        "input_layer = torch.rand(10)\n",
        "\n",
        "# Weight matrix (Number of input neurons, Number of hidden nuerons)\n",
        "w1 = torch.rand(10,20)\n",
        "w2 = torch.rand(20,20)\n",
        "w3 = torch.rand(20,4)\n",
        "\n",
        "# Hidden layers\n",
        "h1 = torch.matmul(input_layer, w1)\n",
        "h2 = torch.matmul(h1,w2)\n",
        "\n",
        "output_layer = torch.matmul(h2,w3)\n",
        "print(output_layer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([251.4403, 235.6309, 236.0042, 220.8700])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf5Sy0yJcJsa"
      },
      "source": [
        "## Building a Neural network - PyTorch style"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lbUXS1xCrBa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "\n",
        "# Class Net inherits from nn.module\n",
        "class Net(nn.Module):\n",
        "  def __init__(self): # Define parameters (tensors, weights)\n",
        "    super(Net,self).__init__()\n",
        "    self.fc1 = nn.Linear(10,20) # Fully connected nodes\n",
        "    self.fc2 = nn.Linear(20,20)\n",
        "    self.output = nn.Linear(20,4)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.output(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6m3r-B2eKBQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f38f4b8-a965-421e-d158-e7cf51bc4813"
      },
      "source": [
        "# 10 nodes of input layer\n",
        "input_layer = torch.rand(10)\n",
        "net = Net() \n",
        "result = net(input_layer)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0687,  0.2870, -0.1255, -0.3945], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2aJ4Jivoual"
      },
      "source": [
        "## Activation Function "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cGv7DgZpbmK"
      },
      "source": [
        "*Linear algebra states that matrix multiplication is linear transformation.*\n",
        "\n",
        "i.e Any layers of NN can be transformed into a single NN. \n",
        "\n",
        "**Consequence** : Deals with linearly seperable datasets.\n",
        "\n",
        "Why Activation Function?\n",
        "\n",
        "* Used to deal with non - linearly seperable datasets.\n",
        "* Activation functions are non - functions.\n",
        "* Used in each layer of NN. Hence making them much more powerfull.\n",
        "\n",
        "Types:\n",
        "\n",
        "\n",
        "1. Sigmoid\n",
        "        1.0 / (1 + np.exp(-1 * x))\n",
        "2. tanh\n",
        "        np.tanh(x)\n",
        "3. ReLU\n",
        "        np.maximum(x, 0)\n",
        "4. Leaky ReLU\n",
        "        np.maximum(0.1x, 0)\n",
        "5. Maxout\n",
        "        max(w1x+b1,w2x+b2)\n",
        "6. ELU\n",
        "        x            x>0\n",
        "        alpha(e^x-1) x<0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03Nfyqkxuj_1"
      },
      "source": [
        "ReLU (Rectifier Linear Unit) activation function\n",
        "\n",
        "* Most used activation function which sets negative inputs to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne7ILHrRh7k0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "8ef63f23-789c-4981-d4c0-8566443dd15b"
      },
      "source": [
        "import torch.nn as nn\n",
        "relu = nn.ReLU()\n",
        "\n",
        "tensor_1 = torch.tensor([2.,-4.])\n",
        "print(relu(tensor_1))\n",
        "\n",
        "tensor_2 = torch.tensor([[2.,-4.],[1.2,0.]])\n",
        "print(relu(tensor_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 0.])\n",
            "tensor([[2.0000, 0.0000],\n",
            "        [1.2000, 0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FyQmRWBwDRI"
      },
      "source": [
        "## Loss Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJy62ePUwFpi"
      },
      "source": [
        "Loss Functions / cost function :\n",
        "\n",
        "Measure of the error.\n",
        "\n",
        "* For regression : least squared loss.\n",
        "* For classification : softmax cross-entropy loss. (Transforms numbers into probabilities)\n",
        "* For more complicated problems ( like object detection) more complicated losses.\n",
        "\n",
        "**Loss functions should be differentiable or else computation of gradients is not possible**. \n",
        "\n",
        "    A function is differentiable at a point when there's a defined derivative at that point. This means that the slope of the tangent line of the points from the left is approaching the same value as the slope of the tangent of the points from the right.\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKfQv5lG37X9"
      },
      "source": [
        "### Softmax Cross Entropy loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oU03YNX4A8t"
      },
      "source": [
        "Softmax: Returns normalized probabilities.\n",
        "\n",
        "Cross Entropy loss : returns -log(probability of correct class predicted). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7WR-5PEvgNb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7cfb0d2b-0494-43b0-b9a6-43129856545c"
      },
      "source": [
        "# Scores for three classes \n",
        "logits = torch.tensor([[3.2,5.1,-1.7]])\n",
        "ground_truth = torch.tensor([0])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "loss = criterion(logits,ground_truth)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.0404)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5rfQPhq6mBN"
      },
      "source": [
        "# Preparing datasets (Computer Vision)\n",
        "\n",
        "Transforming datasets into PyTorch friendly format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZESUj3O4bj5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "36a7064380f644f7a700e985bca772f3",
            "251cade274e2440fbcffec13b6acfb15",
            "d42372a0fbcf4924a17da5eec6060f2c",
            "66f2063fa86c44afa12ad570c8c499e0",
            "600c67f93a934d88ad554f9b44010631",
            "4300cb0334f7403795ec490f3704b581",
            "baf762f037e840cfba67a873e14ce46d",
            "edb84c089f6a4dfa89c774ec0a668bdd"
          ]
        },
        "outputId": "705b23d5-06c1-432d-b0f8-cbc7b8bbed2b"
      },
      "source": [
        "# Using CIFAR-10 color dataset for classification\n",
        "\n",
        "import torch\n",
        "import torchvision # Deals with pretrained datasets and NN\n",
        "import torch.utils.data \n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Transformation of images to torch tensors using tranform.ToTensor()\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914,0.48216,0.44653), # Values for standardizing images (mean and SD of each channel (R,G,B))\n",
        "                          (0.24703,0.24349,0.26159))]\n",
        ")\n",
        "\n",
        "# download: True ( if dataset not in the root folder, then download)\n",
        "# tranform : transform the images to torch.tensors() using the function \n",
        "trainset = torchvision.datasets.CIFAR10(root = './data', train =True, download = True, transform = transform )\n",
        "\n",
        "# train : False ( for test set)\n",
        "testset = torchvision.datasets.CIFAR10(root = './data', train =False, download = True, transform = transform )\n",
        "\n",
        "# Getting data ready for PyTorch\n",
        "# batch_size, shuffle : use 32 random sampled image batches (n 32 batches per Epochs)\n",
        "# num_workers : Number of processors used to fetch.\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle= True, num_workers=4)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset,batch_size=32,shuffle=False,num_workers=4)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36a7064380f644f7a700e985bca772f3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE78-uTwDd9Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58568346-e353-48f0-9509-ac6d565a8b5d"
      },
      "source": [
        "print(testloader.dataset.data.shape, trainloader.dataset.data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 32, 32, 3) (50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tI0CC6GHe8r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "306a1ca1-41c3-448d-9290-f91ec39c5c90"
      },
      "source": [
        "print( testloader.batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3SA5eQrIJiY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd0e4c97-0cb1-4682-e741-bc0fb80c95e1"
      },
      "source": [
        "print(trainloader.sampler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.sampler.RandomSampler object at 0x7fc76dc0b9b0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGQWwtZIud-M"
      },
      "source": [
        "# Training NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLMQbRx7up0j"
      },
      "source": [
        " NN Pipeline:\n",
        "1. Initialize neural networks with random weights.\n",
        "\n",
        "for mini batch :\n",
        "  2. Do a forward pass **(Weighted sum + Activation function)**.\n",
        "  3. Calculate the **loss function** (1 number).\n",
        "---\n",
        "4. Calculate the gradients using backporp\n",
        "  with **Optimizer**.\n",
        "5. Change the weights based on gradients.\n",
        "        SGD : weight -= weight_gradient * learning_rate\n",
        "\n",
        "\n",
        "Training pipeline :\n",
        "\n",
        "1. Initialize model\n",
        "2. Define loss function (criterion)\n",
        "3. Define optimizer with learning rate for gradient descnet \n",
        "  * Optimizer : It is the way of searching/optimizing weights in NN from the search space to reduce loss.\n",
        "  * Adam : Adaptive Moment Estimation (Adam) is method that computes adaptive learning rates for each parameter.\n",
        "    * Learning rate used to increase the rate of descent to optimim (minimum loss) \n",
        "4. Forward step to calculate prediction \n",
        "5. Forward step to calculate loss with respect to the deined criterion\n",
        "6. Backward step to calculate partial derivatives (hyperparameters - weights and biases) with respect to the computational graphs.\n",
        "7. Use optimizer to optimize the weights and biases.\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3fLL6wVwhAU"
      },
      "source": [
        "## Neural Network - PyTorch style"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI1XIJ4EcJm4"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwY1msToIQWN"
      },
      "source": [
        "# Contd. CIFAR10 Example\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F # Functional API\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    # Fully connected layer 1 with 32x32 of 3 channels(RGB) and 500 units in hidden layer\n",
        "    self.fc1 = nn.Linear(32*32*3,500)\n",
        "    self.fc2 = nn.Linear(500,10) # 10 units in output layer for 10 classes\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.fc1(x)) # Apply relu (non -linearality) in the hidden layer\n",
        "    return self.fc2(x)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gysolbQ9yWtY"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx4yy0CxyVaL"
      },
      "source": [
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss() # Loss function\n",
        "optimizer = optim.Adam(net.parameters(),lr = 3e-4) # Adam optimizer with the object parameters and learning rate\n",
        "\n",
        "for epoch in range(10): # loop over the dataset multiple times\n",
        "  for i, data in enumerate(trainloader,0):\n",
        "\n",
        "    # Get the inputs\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.view(-1,32*32*3) # Rearranges into a vector\n",
        "\n",
        "    # Zero the parameter gradients inorder to not accumulate gradients from previous iteration\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward + backward + optimize\n",
        "    outputs = net(inputs) # Forward step results in prediction\n",
        "    loss = criterion(outputs, labels) # Loss function\n",
        "    loss.backward() # calculate Gradient \n",
        "    optimizer.step() # Optimize weights w.r.t optimizer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGxjpjuC5-X6"
      },
      "source": [
        "## Making predictions using model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugiuxOX63PC5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a78423a6-cb93-4bec-f7b6-30bb2dc61cee"
      },
      "source": [
        "correct, total = 0,0\n",
        "predictions = []\n",
        "net.eval() # Setting the model to evaluation for making predictions\n",
        "\n",
        "for i, data in enumerate(testloader,0):\n",
        "  inputs, labels = data\n",
        "  inputs = inputs.view(-1,32*32*3)\n",
        "  outputs = net(inputs) # Feed forward\n",
        "  _, predicted = torch.max(outputs.data,1) # returns the max prob as outpus\n",
        "  predictions.append(outputs)\n",
        "  total += labels.size(0)\n",
        "  correct += (predicted == labels).sum().item() # Number of correct predictions\n",
        "\n",
        "print(\"accuracy :\", (100 * correct/total))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 53.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzgSMgveQhFf"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "his4yGhIQpsO"
      },
      "source": [
        "## Convolution Operator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJMSPqXMQtrM"
      },
      "source": [
        "Neural Networks on images\n",
        "\n",
        "*  All relations between features captured.\n",
        "  *  Computationally inefficient.\n",
        "  * May overfit due to many parameters.\n",
        "\n",
        "Convolutional Neural Network in images\n",
        "\n",
        "* Units connected to only few units from previous layers. ( selected features )\n",
        "* Units share weights.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtFXL1EqToX_"
      },
      "source": [
        "Convolution:\n",
        "\n",
        "Two operation:\n",
        "\n",
        "1. Convolve (Dot product)\n",
        "  * Dot product of filter/Kernel with corresponding pixels of the image and place the result in the center pixel of image.\n",
        "  * Depth dimention should match of filter and image dimentions.\n",
        "    * Image dimention (32,32,**3**)\n",
        "    * Filter dimention (5,5,**3**)\n",
        "2. Sliding window (Stride)\n",
        "  * Slide the kernel/filter along x axis for stride distance.\n",
        "\n",
        "Reuslt: Activation Maps.\n",
        "\n",
        "3. Padding\n",
        "  * Padding the activation map to match the size of image. \n",
        "    * Adding zeros at the side of the image.\n",
        "\n",
        "\n",
        "\n",
        "Convolution layer contains several activation maps.\n",
        "\n",
        "Goal of CNN: \n",
        "\n",
        "* Learn different weighted filters that produces different activation maps corresponding to different features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vFBOHtSZAL6"
      },
      "source": [
        "## Convolutions in PyTorch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50pAN4zjZGXD"
      },
      "source": [
        "### OOP-based(torch.nn)\n",
        "\n",
        "Parameters:\n",
        "\n",
        "* in_channels(int) : Number of channels in input.   \n",
        "* out_channels(int) : Number of channels produced by the convolution.\n",
        "* Kernel_size(int or tuple) : Size of the kernel/filter.\n",
        "* Stride (int or tuple, optional) : Stride of the convolution . Default:1\n",
        "* Padding ( int or tuple, optional) : Zero-padding.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmuwXv7bETRw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "163b4047-3526-409b-ffe5-f7c8bce25ee9"
      },
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "\n",
        "# Mini batch of 16 images(32,32,3)\n",
        "image = torch.rand(16,3,32,32)\n",
        "# Number of out_feature channels can be changed\n",
        "conv_filter = torch.nn.Conv2d(in_channels =3, out_channels =1, kernel_size =5, stride =1, padding =0)\n",
        "output_feature = conv_filter(image)\n",
        "\n",
        "print(output_feature.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dReS69k8aiKC"
      },
      "source": [
        "### Functional (torch.nn.functional)\n",
        "\n",
        "Parameters:\n",
        "\n",
        "* input (minibatch x iH x iW) : input tensor of shape.\n",
        "* weight (out_channels x in _channels x kH x KW) - Shape of the filter.\n",
        "* Stride (sH,sW) : The stride of the convolving kernel.\n",
        "* Padding (Default - 0) : Implicit zero padding on both sides of the input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfLqNjyJaq2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4c2da4c-4a45-48fd-8126-6703dac4479d"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "image = torch.rand(16,3,32,32)\n",
        "filter = torch.rand(1,3,5,5) # Number of output feature channels can be changed(First parameter)\n",
        "out_feat_F = F.conv2d(image,filter,stride=1,padding=0)\n",
        "\n",
        "print(out_feat_F.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In9yghYajYRF"
      },
      "source": [
        "## Pooling operator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbxslAOEjdBT"
      },
      "source": [
        "**Convolution Layer**\n",
        "* Extract different features. (**Feature maps**)\n",
        "\n",
        "**Pooling Layer**\n",
        "\n",
        "* Select most dominant features or combine different features.( **Feature Selection**)\n",
        "\n",
        "Why?\n",
        "\n",
        "* Lower the resolution of the images (downsampling) making computation efficient.\n",
        "* Making learning invarient to translation.(robust to shifting or movements of the image)\n",
        "\n",
        "Types:\n",
        "\n",
        "\n",
        "1.   Max-Pooling\n",
        "  *  Returns the maximum of the pixel map.\n",
        "  *  Typically, 2x2 filter with stride 2 over the activation map.\n",
        "\n",
        "2.   Average Pooling\n",
        "  * Returns the average of the pixel map.\n",
        "  * Typically, 2x2 filter with stride 2 over the activation map.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NpQ7WYgrZj-"
      },
      "source": [
        "### Max-pooling in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qojuYtrnriTC"
      },
      "source": [
        "#### OOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACFfJGaRjcVb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bdf6d04f-f878-4f0a-d2a2-f5d992cea4df"
      },
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "\n",
        "# [mini-batch size, height, depth, weight]\n",
        "im = torch.Tensor([[[[3,1,3,5],[6,0,7,9],[3,2,1,4],[0,2,4,3]]]])\n",
        "max_pooling = torch.nn.MaxPool2d(2) # Kernel size 2\n",
        "output_feature = max_pooling(im)\n",
        "\n",
        "print(output_feature)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[6., 9.],\n",
            "          [3., 4.]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iroDUHPVrmCz"
      },
      "source": [
        "#### Functional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsp7UUZQr99S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e73c7e03-63c2-4db2-dd86-aa99596685e4"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# [mini-batch size, height, depth, weight]\n",
        "im = torch.Tensor([[[[3,1,3,5],[6,0,7,9],[3,2,1,4],[0,2,4,3]]]])\n",
        "\n",
        "output_feature_F = F.max_pool2d(im,2)\n",
        "\n",
        "print(output_feature)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[6., 9.],\n",
            "          [3., 4.]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI5Ql2t3tNJb"
      },
      "source": [
        "### Average-Pooling in PyTorch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4GUEoZqtUw9"
      },
      "source": [
        "#### OOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiE2AhhEtKSB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7df1c34c-270a-4b50-bc12-184225cf22e8"
      },
      "source": [
        "import torch\n",
        "import torch.nn \n",
        "\n",
        "im =  torch.Tensor([[[[3,1,3,5],[6,0,7,9],[3,2,1,4],[0,2,4,3]]]])\n",
        "avg_pooling = torch.nn.AvgPool2d(2)\n",
        "output_feature = avg_pooling(im)\n",
        "\n",
        "print(output_feature)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[2.5000, 6.0000],\n",
            "          [1.7500, 3.0000]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhvdnztjtXMY"
      },
      "source": [
        "#### Functional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piOeBo0VtYzr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bc1b8669-9df1-4608-82f5-f8743361c308"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "im =  torch.Tensor([[[[3,1,3,5],[6,0,7,9],[3,2,1,4],[0,2,4,3]]]])\n",
        "output_feature_F = F.avg_pool2d(im,2)\n",
        "\n",
        "print(output_feature_F)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[2.5000, 6.0000],\n",
            "          [1.7500, 3.0000]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wno76UE9x7qT"
      },
      "source": [
        "## Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNGNrWjCy0op"
      },
      "source": [
        "CNN is a Neural network comprising of the convolutional layer, pooling layers and fully connected layers.\n",
        "\n",
        "CNN pipeline:\n",
        "\n",
        "    Convolution layer -> Pooling layer -> Flattening -> Fully connected layers\n",
        "\n",
        "AlexNet architecture:\n",
        "\n",
        "* Architecture that revolutionised use of CNN.\n",
        "* Developed for ImageNet Classification and consists of \n",
        "  *   5 Convolutional layers\n",
        "  *   3 Max pooling layers\n",
        "  *   3 fully connected layers\n",
        "\n",
        "Output: Classification into 1000 different classes \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1J1hIfU1K0p"
      },
      "source": [
        "## AlexNet in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C60M9hNnvt8M"
      },
      "source": [
        " class AlexNet(nn.Module):\n",
        "\n",
        "  # Parameters taken from paper.\n",
        "  def __init__(self,num_classes = 1000):\n",
        "    super(AlexNet,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,64, kernel_size=11, stride=4, padding=2)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3,stride=2)\n",
        "    self.conv2 = nn.Conv2d(64,192,kernel_size=5, padding=2)\n",
        "    self.conv3 = nn.Conv2d(192,384,kernel_size=3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(384,256,kernel_size=5, padding=2)\n",
        "    self.conv5 = nn.Conv2d(256,256,kernel_size=5, padding=2)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((6,6))\n",
        "    self.fc1 = nn.Linear(256*6*6,4096)\n",
        "    self.fc2 = nn.Linear(4096,4096)\n",
        "    self.fc3 = nn.Linear(4096, num_classes)\n",
        "\n",
        "  # Defining CNN\n",
        "  def forward(self,x):\n",
        "    x = self.relu(self.conv1(x)) # Pass image to conv1\n",
        "    x = self.maxpool(x)\n",
        "    x = self.relu(self.conv2(x))\n",
        "    x = self.maxpool(x)\n",
        "    x = self.relu(self.conv3(x))\n",
        "    x = self.relu(self.conv4(x))\n",
        "    x = self.relu(self.conv5(x))\n",
        "    x = self.maxpool(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0),256*6*6)\n",
        "    x = self.relu(self.fc1(x))\n",
        "    x = self.relu(self.fc2(x))\n",
        "    return self.fc3\n",
        "\n",
        "net = AlexNet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iN0bxv-CL9_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "50929374-771d-4464-ae84-50271cd353f6"
      },
      "source": [
        "net"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (conv3): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(384, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (conv5): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPcheqaIFG8b"
      },
      "source": [
        "## Training Fully Connected CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL4OC7BHd0O4"
      },
      "source": [
        "## 1. Dataloaders ( Loading train and test data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uudWU_JECSw8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "cf37264e-52bb-4a10-9e4c-919806c75c50"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data',train = True, transform=transform, download=True )\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root= './data', train = False, download = True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 128, shuffle = True, num_workers = 2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = 128, shuffle = False, num_workers = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NutHU0KhrBf"
      },
      "source": [
        "## Building CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5_nCG7Udwff"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  # Define parameters (layers..)\n",
        "  def __init__(self,num_classes = 10):\n",
        "    super(CNN,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels= 3, out_channels=32, kernel_size=3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels= 32, out_channels=64, kernel_size=3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.fc = nn.Linear(128*4*4, num_classes) # (out_channels * height * width) <- Result of pooling and conv\n",
        "\n",
        "  # Applying the parameters to the input\n",
        "  def forward(self,x):\n",
        "    x = self.pool(F.relu(self.conv1(x))) # Functional relu\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.pool(F.relu(self.conv3(x)))\n",
        "    x = x.view(-1,128*4*4) # Squeze into a single D vector (Flattening)\n",
        "    return self.fc(x)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuqB7poflsYM"
      },
      "source": [
        "## Training with optimizer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EEoevAFwFmM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0aba44a-487f-4908-a4f6-daf2b5e686ef"
      },
      "source": [
        "net = CNN() # Instantiate object from class Net\n",
        "criterion = nn.CrossEntropyLoss() # Instantiate cross entropy loss \n",
        "optimizer = optim.Adam(net.parameters(),lr = 3e-4) \n",
        "\n",
        "# Training ( loop over trainloader )\n",
        "\n",
        "for epoch in range(10):\n",
        "  for i,data in enumerate(trainloader,0):\n",
        "    # Get the inputs\n",
        "    inputs, labels = data\n",
        "\n",
        "    # Zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward + backward + optimize\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"Finished training\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRAePtjLqwU-"
      },
      "source": [
        "## Evaluating the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01pXy-ZGnbbt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9b04cad-4149-490b-b5cd-5d36813b299c"
      },
      "source": [
        "correct, total =0,0\n",
        "predictions = []\n",
        "net.eval()\n",
        "\n",
        "for i, data in enumerate(testloader,0):\n",
        "  inputs, labels = data\n",
        "  outputs = net(inputs)\n",
        "  _,predicted = torch.max(outputs.data,1)\n",
        "  predictions.append(outputs)\n",
        "  total += labels.size(0)\n",
        "  correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"accuracy of CNN :\", 100*correct/total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of CNN : 70.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBnN3p9-r51V"
      },
      "source": [
        "# Sequential Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUfFgS71sEUR"
      },
      "source": [
        "* PyTorch tool usefull when building large NN.\n",
        "* Sequential module helps in making code more modular (usefull in feed forward networks).\n",
        "* More OO based approach and allows to change parts(modules) independently of each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_stbC4urnYb"
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "\n",
        "  # Parameters taken from paper.\n",
        "  def __init__(self,num_classes = 1000):\n",
        "    super(AlexNet,self).__init__()\n",
        "    self.features = nn.Sequential( # Sequential module, order matters (Convolutional layers)\n",
        "      nn.Conv2d(3,64, kernel_size=11, stride=4, padding=2), nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3,stride=2),\n",
        "      nn.Conv2d(64,192,kernel_size=5, padding=2), nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(192,384,kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(384,256,kernel_size=5, padding=2), nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(256,256,kernel_size=5, padding=2), nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3,stride=2),)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((6,6))\n",
        "    self.classifier = nn.Sequential( # Sequential module (Fully Connected layers)\n",
        "        nn.Dropout(),nn.Linear(256*6*6,4096), nn.ReLU(inplace=True), # Dropout (few units) used to avoid overfitting\n",
        "        nn.Dropout(), nn.Linear(4096,4096), nn.ReLU(inplace=True),\n",
        "        nn.Dropout(), nn.Linear(4096, num_classes))\n",
        "\n",
        "  # Defining CNN w.r.t each sequential module\n",
        "  def forward(self,x):\n",
        "    x = self.features(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0), 256*6*6)\n",
        "    x = self.classifier(x)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUO3ent21u1c"
      },
      "source": [
        "# The problem of overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p23M63dY3OPC"
      },
      "source": [
        "Model works very well on training set, but worse on the test set.\n",
        "\n",
        "Reason:\n",
        "\n",
        "* Very complicated non-smooth hypothesis (seperator).\n",
        "\n",
        "**Bias and Variance tradeoff**:\n",
        " \n",
        "* Bias \n",
        "  * Inability to **capture true relationship** between independent and dependent variables.\n",
        "\n",
        "* Variance\n",
        "  * **Mean squared difference**  between prediction and actual value.\n",
        "\n",
        "        low bias -> high variance\n",
        "        high bias -> low variance\n",
        "\n",
        "**Overfitting: High variance ( high difference of accuracy between training and test set)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7NKH2tnOP3H"
      },
      "source": [
        "## Prevent Overfitting:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yDsqKhlOUTe"
      },
      "source": [
        "\n",
        "* Training different models with changing hyperparameters on training set and testing on test set may lead to contamination of test set.\n",
        "\n",
        "Solution : Cross validation of model with validation set and then on test on test set.\n",
        "\n",
        "  * Training set : Train the model\n",
        "  * Validation set : Select the model\n",
        "  * Testing set : test the model\n",
        "\n",
        "Note: Testing set used only ones or few times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsY5Cd91BHs8"
      },
      "source": [
        "### Using validation sets in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcvzTOw5xi82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "269cd815-dffb-4245-b469-a8db7879d6fd"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "indices = np.arange(50000) # train and validation split based on indices \n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# subsetrandomsampler used to select random samples from the indices for training  \n",
        "train_loader = torch.utils.data.DataLoader(torchvision.datasets.CIFAR10(root ='./data', train = True, download =True, transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))])),\n",
        "                                            batch_size = 1, shuffle = False, sampler = torch.utils.data.SubsetRandomSampler(indices[:45000]))\n",
        " \n",
        "val_loader = torch.utils.data.DataLoader(torchvision.datasets.CIFAR10(root ='./data', train = True, download =True, transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))])),\n",
        "                                            batch_size = 1, shuffle = False, sampler = torch.utils.data.SubsetRandomSampler(indices[45000:50000]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re_OsLrGOD6N"
      },
      "source": [
        "### Regularization techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YRVE1XsOkw_"
      },
      "source": [
        "Techniques used in train to give better predictions, generalize well and avoid overfitting.\n",
        "\n",
        "*   **L2 - regularization** :\n",
        "  * Adding value to loss function that penalizes large weights.\n",
        "      * loss + sum of the squared norm of weight matrices * regularization parameter. \n",
        "  * Used in regression and svm.\n",
        "  * Add `weight_decay`\n",
        "          optim.Adam(net.parameters(), lr = 3e-4, weight_decay=0.0001)\n",
        "*  **Dropout** :\n",
        "  * During forward pass, there is a probability p to be dropped out from computation. \n",
        "  * By doing so units are forced to not be dependent on surrounding units. (architecture changing as different units are removed during each iteration)\n",
        "  * Typically used in fully connected layers. \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "self.classifier = nn.Sequential (\n",
        "  nn.Dropout (p =0.5), # Drop each unit with probability 50%\n",
        "  nn.Linear(256*6*6,4096),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Dropout(p=0.5),\n",
        "  nn.Linear(4096,4096),\n",
        "  nn.ReLU(inplace = True),\n",
        "  nn.Linear(4096, num_classes),\n",
        ")\n",
        "\n",
        "```\n",
        "* **Batch-normalization**\n",
        "  *  Normalization is the process of scaling the data values to a standard scale.\n",
        "           Normalization - [0 to 1]\n",
        "           Standardization - [x- mean / standard deviation]\n",
        "    * Why?\n",
        "    \n",
        "      * Larger weights can cause im balanced gradients, which may ultimately leads to exploding gradient problem [local minima].\n",
        "  * **Batch normalization applied to layers normalizes the output of the activation function for the units of the layer applied**. \n",
        "      1. Normalize output from activation function.\n",
        "              z = x-M/ S.d\n",
        "      2. Multiply normalized output by arbitrary parameter, g.\n",
        "              z*g\n",
        "      3. Add arbitrary parameter, b, to resulting product.\n",
        "              (z *g)+b\n",
        "      * Mean(M), Standard deviation (d), g, b are trainable parameters.\n",
        "\n",
        "  *  Batch normalization computes mean and variance etc. of the mini batch for each feature and then normalises features based on these stats. Insert BatchNorm2d after the activation layer of the features to normalize the batch of features.\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(num_features = 64, eps = 1e-05, momentum = 0.9)\n",
        "\n",
        "* **Early stopping** : \n",
        "    * Checks the accuracy of the validation set for each epoch. If the accuracy is stagnent or decreased, then training is terminated. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lk2BJbeyrir"
      },
      "source": [
        "### Hyperparameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWec9ERqy2MK"
      },
      "source": [
        "Question: How to choose all these hyperparameters(l2 regualarization, dropout parametr, optimizers (Ada vs gradient descent), batch-norm momentum and epsilon, number of epochs for early stopping etc)?\n",
        "\n",
        "Answer:\n",
        "\n",
        "* Train many networks with different hyperparameters (typically use random values for them).\n",
        "* Test them on validation set.\n",
        "* Use best performing net in the validation set to know the expected accuracy of the network in new data.\n",
        "\n",
        "**Note: Very important to set the mode of the net** (`model.train()`, `model.eval()`)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVkQFk6N7p-e"
      },
      "source": [
        "# Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DpgAfu07vJ3"
      },
      "source": [
        "The deeper the progress in the CNN, the more abstract the features become.\n",
        "\n",
        " **Consequence**: the low level features or layers are more general to a large degree dataset dependent.\n",
        "\n",
        "Transfer Leaning: Using a pretrained model trained on large dataset and to finetune the model for the specific use case.\n",
        "\n",
        "* Usefull to train in less time and to train small datasets without overfitting.\n",
        "\n",
        "**Fine tuning** :\n",
        "\n",
        "1. **Fine tune everything**.\n",
        "    Eg. \n",
        "\n",
        "      1. Trained model on CIFAR10 and saved the model as cifar10.pth\n",
        "      2. The penaltimate layer has dimentions of 1024(features) * 4 * 4 (spatial dimention).\n",
        "      3. Use this pretrained model to train CIFAR100 dataset which is much smaller.\n",
        "\n",
        "      Finetuning the model using CIFAR10.\n",
        "\n",
        "      ```\n",
        "      #Instantiate the model \n",
        "      model = Net()\n",
        "\n",
        "      #Load the parameters from the old model trained on CIFAR10\n",
        "      model.load_state_dict(torch.load('cifar10_net.pth'))\n",
        "\n",
        "      # Change the number of units in the last layer (always correspond to the number of classes)\n",
        "      model.fc = nn.Linear(4 * 4* 1024, 100)\n",
        "\n",
        "      # Train and evaluate the model ( same from scratch)\n",
        "      model.train()\n",
        "      ```\n",
        "2. **Freeze all the layer except the last layer** during back propagation and fine tune only the last layer.\n",
        "  * Typically done if dataset is too small.\n",
        "\n",
        "\n",
        "      \n",
        "      #Instantiate the model \n",
        "      model = Net()\n",
        "\n",
        "      #Load the parameters from the old model trained on CIFAR10\n",
        "      model.load_state_dict(torch.load('cifar10_net.pth'))\n",
        "\n",
        "      # Freeze all the layers except the final one\n",
        "      for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "      \n",
        "      # Change the number of output units\n",
        "      model.fc = nn.Linear( 4 * 4 * 1024, 100)\n",
        "\n",
        "      # Train and evaluate the model ( same from scratch)\n",
        "      model.train()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDZil12EIrCk"
      },
      "source": [
        "## Torchvision library\n",
        "\n",
        "Library for pretrained models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MGa09oNIfhv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e0eb5c-665d-464b-834a-3dcb9efa4346"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "# Donwload the resnet dataset from torchvision\n",
        "model = torchvision.models.resnet18(pretrained = True)\n",
        "\n",
        "#model.fc = nn.Linear(512,num_classes)\n",
        "model.layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleAttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-73835136ad0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#model.fc = nn.Linear(512,num_classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 772\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleAttributeError\u001b[0m: 'ResNet' object has no attribute 'layers'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svFS83nZJH3R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}